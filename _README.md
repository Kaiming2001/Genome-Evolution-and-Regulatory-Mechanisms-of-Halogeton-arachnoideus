Genome-Evolution-and-Regulatory-Mechanisms-of-Halogeton-arachnoideus/
├── envs/
│   ├── hifiasm.yml     # Environment for hifiasm to PacBio HiFi genome assembly.
│   ├── samblaster.yml      # Environment for samblaster
│   ├── Infernal.yml        # Environment for Infernal to ncRNA annotation  
│   └── tRNAscan.yml        # Environment for tRNAscan-SE to tRNA prediction
│
├── scripts/
│   ├── genome_assembly.sh      # Genome assembly workflow using HiFi reads
│   ├── genome_mapping.sh       # Read mapping and BAM generation
│   ├── fastaFileStatics_NoBioPerl.pl      # FASTA statistics script for N50
│   ├── GO.R        # GO enrichment analysis and visualization
│   ├── Trans_TPM.sh        # TPM normalization from RNA-seq expression data
│   ├── DEG.R       # Differential expression analysis 
│   ├── GRN.R       # Gene regulatory network (GRN) construction 
│   └── utils/       # Utility scripts for EvidenceModeler (EVM) and annotation integration
│       ├── EVM.merge.cmd.pl
│       ├── EVM.prepare.pl
│       ├── EVM.run.cmd.pl
│       ├── EVM_Partition_Combin.pl
│       └── split_fasta.pl            
│
├── results/
│   ├── restored_GO.pl.out      # Output from GO annotation
│   ├── Tran_sample.txt     # Transcriptome sample metadata (sample IDs, conditions)
│   ├── gene_count_matrix.csv       # Raw gene count matrix for DEG analysis
│   ├── 200.TPM.xlsx        # TPM matrix under 200 mM salt stress condition
│   ├── 200cy_edges_strong.csv      # Strongly connected edges in GRN (200 mM condition)  
│   ├── 200cy_nodes_strong.csv      # Node attributes in GRN (200 mM condition)
│   ├── 400.TPM.xlsx        # TPM matrix under 400 mM salt stress condition
│   ├── 400cy_edges_strong.csv      # Strongly connected edges in GRN (400 mM condition)
│   └── 400cy_nodes_strong.csv      # Node attributes in GRN (400 mM condition)
│   └── TF-TF/ 
│       ├── 200TF.TPM.xlsx      # Only the values of TF TPM under 200 mM salt stress condition
│       ├── 200.upregulated_TF_edges.csv        # Strongly connected edges, upregulated edges denote stronger regulatory interactions at 24 h, whereas 'down' indicates stronger interactions at 6 h (200 mM condition).
│       ├── 200.downregulated_TF_edges.csv   
│       ├── 400TF.TPM.xlsx      # Only the values of TF TPM under 400 mM salt stress condition
│       ├── 400_upregulated_TF_edges.csv        # Strongly connected edges, upregulated edges denote stronger regulatory interactions at 24 h, whereas 'down' indicates stronger interactions at 6 h (400 mM condition).
│       └── 400_downregulated_TF_edges.csv
│
└──README.md                                  

# Genome Assembly

This repository provides scripts and environment configuration for running [hifiasm] genome assembly, including BAM-to-FASTA conversion and HiFi-only assembly.
---
## 1. Environment Setup
First, install [Anaconda](https://docs.conda.io/en/latest/miniconda.html) or Miniconda.  
Then create the conda environment from the provided YAML file:
```bash
conda env create -f envs/hifiasm.yml
conda activate hifiasm 
```
---
## 2. Running the pipeline： scripts/genome_assembly.sh
The pipeline starts from a PacBio HiFi CCS BAM file (e.g., input.bam).
```bash
bash scripts/genome_assembly.sh input.bam
```

# Genome mapping

This section describes how to scaffold contigs using [HapHiC] v1.0.6(https://github.com/zengxiaofei/HapHiC), from installation to building pseudomolecules.
---
## 1. Install HapHiC and environment
```bash
git clone https://github.com/zengxiaofei/HapHiC.git
conda env create -f HapHiC/conda_env/environment_py310.yml
conda activate haphic
conda env create -f envs/samblaster.yml
```
---
## 2. Running the pipeline: scripts/genome_mapping.sh
```bash
bash genome_mapping.sh contigs.fa read1.fq.gz read2.fq.gz nchrs prefix
```
The script Step 10: juicebox.sh is automatically generated by HapHiC.
Please check the HapHiC installation path in the script and update it.

# Genome annotation

## 1. gene annotation
1.TE annotation and mask: Use [EDTA] pipeline v2.2.2(https://github.com/oushujun/EDTA). [TEsorter] v1.2(https://github.com/zhangrengang/TEsorter) employed to reclassify “LTR/unknown” elements. And the TE library created by EDTA was used to mask the whole genome sequences with RepeatMasker v.4.1.0.
```bash
perl /path/to/EDTA/bin/EDTA.pl --genome species.FINAL.fa --sensitive 1 --anno 1 -- threads 10
grep "ltr_identity" ./species.FINAL.fa.mod.EDTA.intact.gff3 | sed 's/.*ltr_identity=\([0-9.]*\).*/\1/' > ltr_identity_values.txt  #This data used for plotting the insertion time of LTR.
/path/to/TEsorter ./species.FINAL.fa.mod.EDTA.TElib.fa -db rexdb-plant
```
The result species.FINAL.fa.mod.MAKER.masked was the fa to next predict genes.

2.Predict the structure of protein-coding genes on the "masked" genome. Gene annotation was conducted through an integrated approach combining homology-based, transcriptome-based, and ab initio predictions.
homology-based: "protein.fasta" are downloaded from publicly available databases; "genome.fa" refers to marked genome sequence.
```bash
wget http://www.ebi.ac.uk/~birney/wise2/wise2.4.1.tar.gz
tar zxf wise2.4.1.tar.gz -C /opt/biosoft/
cd /opt/biosoft/src
make all
genewise protein.fasta genome.fa -tfor -both -gff > output.gff  
```
transcriptome-based: Install the software [Fastp] v0.20.0(https://github.com/OpenGene/fastp), [HISAT2] v2.1.0(https://github.com/DaehwanKimLab/hisat2), [StringTie] v2.2.1(https://github.com/gpertea/stringtie), [gffread] v0.12.7(https://github.com/gpertea/gffread) and [transdecoder] v5.5.0(https://github.com/TransDecoder/TransDecoder).
```bash 
fastp -i R1.fastq.gz -o R1.clean_1.fq.gz -I R2.fastq.gz -O R2.clean_2.fq.gz
hisat2-build genome.fa genome_index
hisat2 -p 5 -x genome_index -1 R1.clean_1.fq.gz -2 R2.clean_2.fq.gz -S species.sam --summary-file species.hisat.out;samtools sort species.sam -O BAM -T species -l 3 -o species.sort.bam  && rm species.sam
stringtie -p 5 species.sort.bam -o species.gtf 
gffread species.gtf -g genome.fa -w transcripts.fa
TransDecoder.LongOrfs -t transcripts.fa 
TransDecoder.Predict -t transcripts.fa
```
ab initio: [AUGUSTUS] v3.3.3
```bash
wget -c http://bioinf.uni-greifswald.de/augustus/binaries/augustus.current.tar.gz
tar -xzvf augustus.current.tar.gz
cd augustus
make
run_BUSCO.py -i genome.fa -o Chr_dpecies -l ./BUSCO_data/embryophyta_odb10 -m geno -c 160 -sp arabidopsis --long
cp -r Chr_species/run_*/augustus_output/retraining_parameters .ab/BUSCO  #Copy the parameter file to the AUGUSTUS configuration directory.
augustus --species=BUSCO genome.fa --softmasking=1 --gff3=on > augustus.gff
```
EVM: Install the software [EVidenceModeler] V1.1.1(https://github.com/EVidenceModeler/EVidenceModeler/wiki); ./genewise ./transcripts ./abinitio are folders that store the results of homology-based, transcriptome-based, and ab initio methods respectively.
```bash
perl scripts/utils/split_fasta.pl genome.fa > ./genome_split
perl scripts/utils/EVM.prepare.pl /path/to/EVM_r2012-06-25 ./abinitio ./genewise ./transcripts ./genome_split ./evm
perl scripts/utils/EVM.run.cmd.pl /path/to/EVM_r2012-06-25 ./genome_split ./evm scripts/utils > ./evm/01.split_prepare.sh
parallel -j 20 < ./evm/01.split_prepare.sh
cat ./evm/evm_for_each_chr/*/split_evm_running.sh > ./evm/02.split_run.sh
parallel -j 20 < ./evm/02.split_run.sh
cat ./evm/evm_for_each_chr/*/commands.list > ./evm/03.running.sh
parallel -j 20 < ./evm/03.running.sh
perl scripts/utils/EVM.merge.cmd.pl ./evm/evm_for_each_chr /path/to//EVM_r2012-06-25 > ./evm/04.merge.sh
parallel -j 20 < ./evm/04.merge.sh
gffread result.gff -g genome.fa -x cds.fa -y protein.fa
```

## 2. RNA annotation
miRNA and snRNA
```bash
conda env create -f envs/Infernal.yml
wget http://ftp.ebi.ac.uk/pub/databases/Rfam/CURRENT/Rfam.cm.gz
gunzip Rfam.cm.gz
wget http://ftp.ebi.ac.uk/pub/databases/Rfam/CURRENT/Rfam.clanin
cmpress Rfam.cm
nohup cmscan -Z 843 --cut_ga --rfam --nohmmonly --fmt 2 --tblout sample.tblout -o sample.result --clanin Rfam.clanin Rfam.cm genome.fa &
awk 'BEGIN{OFS="\t";}{if(FNR==1) print "target_name\taccession\tquery_name\tquery_start\tquery_end\tstrand\tscore\tEvalue"; if(FNR>2 && $20!="=" && $0!~/^#/) print $2,$3,$4,$10,$11,$12,$17,$18; }' my-genome.tblout > genome.tblout.final.xls
wget https://ftp.ebi.ac.uk/pub/databases/Rfam/CURRENT/database_files/family.txt.gz
gunzip family.txt.gz
awk 'BEGIN {FS=OFS="\t"} {print $1 "\t" $2 "\t" $19}' rfam.txt > output2.txt
less output2.txt | awk 'BEGIN {FS=OFS="\t"}{split($3,x,";");class=x[2];print $1,$2,$3,$4,class}' > rfam_anno.txt
awk 'BEGIN{OFS=FS="\t"}ARGIND==1{a[$2]=$5;}ARGIND==2{type=a[$1]; if(type=="") type="Others"; count[type]+=1;}END{for(type in count) print type, count[type];}' rfam_anno.txt sample.tblout.xls >sample.ncRNA.statistic
```
tRNA
```bash
conda env create -f envs/tRNAscan.yml
tRNAscan-SE genome.fa -o tRNA.out -f tRNA.ss -m tRNA.stats
```
rRNA
```bash
wget https://api.ncbi.nlm.nih.gov/datasets/v2/genome/download?filename=ncbi_dataset.zip&ncbi_phid=939B4B1AD2E31AD500004E25DBBC97DE.1.m_3.010
makeblastdb -in genome.fasta -dbtype nucl -parse_seqids -out hara.fa
blastn -query sole.fa -db hara.fa -evalue 1e-6 -outfmt 6 -num_threads 6 -out out_file
```

## 3. function annotation
InterProscan GO: Install the software [InterProscan] v5.52-86.0
```bash
interproscan.sh -f tsv -i Hara.pep.fa -o Hara.pep.fa.tsv -iprlookup -goterms -pa -t p
awk -F "\t" '$11 != "-" {print $1"\t"$11}' Hara.pep.fa.tsv > Hara_GO_mapping.tsv
awk -F "\t" '$9 != "-" {print $1"\t"$9}' Hara.pep.fa.tsv > Hara_InterPro_mapping.tsv
```
SwissProt: Install the software makeblastdb
```bash
makeblastdb -in uniprot_sprot.fasta -dbtype prot -title  uniprot_sprot -parse_seqids -out uniprot_sprot -logfile uniprot_sprot.log
blastp -query Hara.pep -out swiss-prot.out  -db uniprot_sprot -evalue 1e-5 -outfmt 7 
perl func_anno_stat.pl swiss_port.fasta.function swiss-prot.out > result.txt 
cut -f 1  swiss-prot.out.function  |sort |uniq > final.result.txt
```
NR: Install the software diamond
```bash
wget https://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/update_blastdb.pl
./update_blastdb.pl --decompress nr
diamond blastp --db nr --query Hara.pep  --out Hara.pep.nr.out 
cut -f 1 Hara.pep.nr.out |sort |uniq > result.txt
```
KOG
```bash
wget ftp://ftp.ncbi.nih.gov/pub/COG/KOG/kyva 
wget ftp://ftp.ncbi.nih.gov/pub/COG/KOG/kog 
wget ftp://ftp.ncbi.nih.gov/pub/COG/KOG/fun.txt
makeblastdb -in kyva -dbtype prot -title kog -parse_seqids -out kog -logfile kog.log 
blastp -query Hara.pep  -out kog.out  -db kog -evalue 1e-5 -outfmt 7 
cut -f 1 kog.out | grep -v '^#' | sort | uniq > result.txt
```

# Assembly Quality Evaluation

To assess the quality and completeness of the genome assembly, we performed some key evaluations: Contig N50, BUSCO, Quality Value (QV).
## N50: Use scripts/fastaFileStatics_NoBioPerl.pl to calculate N50.
## BUSCO: Perform a BUSCO analysis using the embryophyta_odb10 lineage dataset. 
```bash
busco -i genome.fa -o busco_output -l embryophyta_odb10 -m genome -c 16
```
## QV: Use [Merqury](https://github.com/marbl/merqury) to calculate QV. This estimates consensus quality based on k-mer spectra comparison between raw reads and the assembled genome.
```bash
git clone https://github.com/marbl/merqury.git
cd merqury
make
export PATH=$PWD:$PATH
meryl k=19 count assembly.fasta output asm.meryl
```

# GO enrichment analysis: scripts/GO.R

 GO Enrichment Analysis with [topGO] v.2.58.0.

# Transcriptome analysis under salt stress: scripts/Trans_TPM.sh

1.Process raw reads to remove adaptor sequences and low quality reads with [Fastp].
2.Align clean reads to the reference genome using [HISAT2].
3.The aligned reads were subsequently used to quantify Ttranscript abundance was quantified as Transcripts Per Kilobase Million (TPM) using [StringTie].

# differentially expressed genes (DEGs): scripts/DEG.R

The prepDE.py script (https://github.com/gpertea/stringtie) was used to convert StringTie output into a count matrix for differential expression analysis.
Differential expression genes were identified using [DEseq2] v1.42.0.

# GRN: scripts/GRN.R

Use [GENIE3] v1.28.0 R package to reconstruct salt stress-responsive gene regulatory networks (GRNs).